{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "VoEzBpnu3MCb",
        "hAYmGPz93MCc",
        "TtWVQSg43VMN",
        "dauF4eBmngu3",
        "MSa1f5Uengrz",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "R37pOE0mxs1U",
        "4_0_7-oCpUZd",
        "fgwTeHC70UlE",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "UGLIjy_TPVqu",
        "eLgQ4qwHv50K",
        "qJenfFQ4AEuv",
        "Fze-IPXLpx6K",
        "e5WyxV1XQl2_",
        "ayrGE9VTQrim",
        "wr0obDj7NY-P",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Cardiovascular Risk Prediction"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Ayushi Sharma\n",
        "##### **Team Member 2 -** Palak"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Framingham dataset is a well-known dataset derived from an ongoing study of residents in Framingham, Massachusetts, aimed at predicting the risk of Coronary Heart Disease (CHD) within a 10-year period. This project focuses on building a classification model to predict CHD risk based on an individual’s medical and behavioral features. A key part of the project involves identifying optimal preprocessing techniques to prepare the dataset for effective machine learning analysis.\n",
        "\n",
        "The dataset includes a variety of demographic data (such as sex, age, and education), behavioral data (like smoking habits), and medical information (including blood pressure, diabetes, cholesterol, BMI, glucose levels, and history of stroke or hypertension), all of which are relevant predictors of cardiovascular risk.\n",
        "\n",
        "The initial step in the project involves comprehensive data preprocessing. This includes handling missing values, detecting and treating outliers, and performing feature engineering. Missing values are imputed using realistic, research-backed methods, while outliers are analyzed to determine if they fall within a plausible range before being addressed to minimize data loss. New features are engineered by combining existing variables, such as calculating mean arterial pressure and categorizing glucose levels. Hypothesis testing is used to evaluate the statistical significance and dependency of each feature in relation to the CHD outcome.\n",
        "\n",
        "Following preprocessing, the dataset is divided into training and testing sets using a suitable test ratio. The features in both sets are scaled using MinMaxScaler, based on the distribution in the training set. Due to the imbalance in the target variable (CHD occurrence), SMOTE (Synthetic Minority Over-sampling Technique) is applied to the training set to enhance model training. Three classification algorithms are then trained: Logistic Regression, Decision Tree, and XGBoost. Each model’s performance is evaluated using the Recall score, chosen as the primary metric given the importance of identifying positive CHD cases. The model with the highest Recall on the test set is selected as the final model.\n",
        "\n",
        "The Decision Tree model trained on the original dataset achieves the highest Test Recall score of 87.25%, outperforming all other models and preprocessing variations. This model is further interpreted using SHAP (SHapley Additive exPlanations) values, which reveal that age is the most influential predictor of CHD risk, while sex and diabetes contribute the least.\n",
        "\n",
        "In summary, this project emphasizes the critical role of data preprocessing, feature engineering, and model selection in building an effective CHD risk prediction model. The use of SHAP values enhances model interpretability by identifying the most impactful features. Future work could involve incorporating additional features, experimenting with alternative preprocessing methods, and validating the model on external datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cardiovascular diseases, particularly coronary heart disease (CHD), continue to be a major health concern worldwide. Early identification and risk stratification of individuals susceptible to developing CHD over a 10-year period is critical for targeted intervention and prevention strategies.\n",
        "\n",
        "This project aims to build a predictive machine learning model using the Framingham Heart Study dataset to classify individuals into high-risk and low-risk categories for CHD. The challenge lies in dealing with imbalanced classes, limited positive cases, and ensuring clinical interpretability of the predictions. The final goal is to support healthcare decision-making by identifying high-risk individuals early, ultimately reducing the incidence and healthcare costs associated with coronary heart disease."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoEzBpnu3MCb"
      },
      "source": [
        "##  ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAYmGPz93MCc"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69I99V7F3MCd"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install graphviz\n",
        "import graphviz\n",
        "from IPython.display import SVG, display\n",
        "from graphviz import Source\n",
        "\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from scipy.stats import ttest_1samp, shapiro\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import recall_score, make_scorer, roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "!pip install shap\n",
        "import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jILLVGGx3MCd"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('data_cardiovascular_risk.csv')"
      ],
      "metadata": {
        "id": "c8q942enWGgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv5tYhIq3MCe"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEVxIAwG3MCe"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6iIwiFf3MCf"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwLBo1kh3MCf"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'Number of rows in the dataset: {df.shape[0]}')\n",
        "print(f'Number of columns  in the dataset: {df.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzfHI17E3MCf"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SeMQfeB3MCg"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjhS5eJx3MCg"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DpnPYBa3MCg"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f'Number of duplicated rows in the dataset: {df.duplicated().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzwaDhrJQlnQ"
      },
      "source": [
        "It is expected that **id** column should have all unique values, as it represents one unique person of interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxCRhN0wQxbq"
      },
      "outputs": [],
      "source": [
        "df['id'].duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNCJl0m23MCh"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRRqUq-o3MCh"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(f'There are {df.isna().sum().sum()} missing values in the dataset\\n')\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w8mxWHd3MCh"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(13, 10))\n",
        "sns.heatmap(df.isna())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5h3vjHg3MCh"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfc3H7XB3MCh"
      },
      "source": [
        "On a first look at the dataset, it is found that\n",
        "*   There are **3390 rows and 17 columns**, out of which one is **TenYearCHD** which is the the dependent variable to be predicted\n",
        "*   Two of these features are **not in numerical (int/float) datatype**\n",
        "*   There are **no duplicated data** in the dataset, and all values in **id** column are **unique**\n",
        "*   There are **510 missing values** in the dataset, with **304** of them in **glucose** column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtWVQSg43VMN"
      },
      "source": [
        "##  ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dba-9TcC3VMO"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fQ7jEOW3VMO"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1H_P_KV3VMO"
      },
      "source": [
        "### Variable Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bas0ecSe3VMP"
      },
      "source": [
        "The various features (and their type), which are potential factors for CHD risk, utilised in this Cardiovascular Risk assessment are:\n",
        "\n",
        "*   **id**: Personal identification number (Unique)\n",
        "\n",
        "Demographic:\n",
        "*   **sex**: Male or Female (Nominal)\n",
        "*   **age**: Age of the patient (Continuous)\n",
        "*   **education**: no information provided (**Ordinal assumed**)\n",
        "\n",
        "Behavioral:\n",
        "*   **is_smoking**: Whether or not the patient is a current smoker (Nominal)\n",
        "*   **cigsPerDay**: Number of cigarettes smoked by the person per day on average (Continuous)\n",
        "\n",
        "Medical information:\n",
        "*   **BPMeds**: Whether or not the patient is on blood pressure medication (Nominal)\n",
        "*   **prevalentStroke**: Whether or not the patient previously had a stroke (Nominal)\n",
        "*   **prevalentHyp**: Whether or not the patient was hypertensive (Nominal)\n",
        "*   **diabetes**: Whether or not the patient has diabetes (Nominal)\n",
        "*   **totChol**: Total cholesterol level in mg/dL (Continuous)\n",
        "*   **sysBP**: systolic blood pressure in mmHg (Continuous)\n",
        "*   **diaBP**: diastolic blood pressure in mmHg (Continuous)\n",
        "*   **BMI**: Body Mass Index (Continuous)\n",
        "*   **heartRate**: Heart rate (Continuous)\n",
        "*   **glucose**: glucose level in mg/dL (Continuous).\n",
        "\n",
        "Target variable to predict:\n",
        "*   **TenYearCHD**: 10 year risk of coronary heart disease (CHD) - (Nominal)\n",
        "\n",
        "\n",
        "\n",
        "| Variable         | Description                                                  |\n",
        "|------------------|--------------------------------------------------------------|\n",
        "| `age`            | Age of the patient                                           |\n",
        "| `education`      | Education level (1-4 scale)                                  |\n",
        "| `sex`            | Gender (`M` or `F`)                                          |\n",
        "| `is_smoking`     | Current smoking status (`YES` or `NO`)                       |\n",
        "| `cigsPerDay`     | Number of cigarettes smoked per day                          |\n",
        "| `BPMeds`         | Binary indicator for blood pressure medication use           |\n",
        "| `prevalentStroke` | History of stroke                                            |\n",
        "| `prevalentHyp`   | History of hypertension                                      |\n",
        "| `diabetes`       | Diabetic status (1 = diabetic, 0 = not)                      |\n",
        "| `totChol`        | Total cholesterol (mg/dL)                                    |\n",
        "| `sysBP`          | Systolic blood pressure                                      |\n",
        "| `diaBP`          | Diastolic blood pressure                                     |\n",
        "| `BMI`            | Body Mass Index                                              |\n",
        "| `heartRate`      | Heart rate (beats per minute)                                |\n",
        "| `glucose`        | Glucose level (mg/dL)                                        |\n",
        "| `TenYearCHD`     | 10-year risk of CHD (1 = yes, 0 = no)                        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfVfImiU3VMP"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfaROOHy3VMP"
      },
      "outputs": [],
      "source": [
        "# Splitting the categorical and continuous variables\n",
        "categ_vars = ['sex', 'education', 'is_smoking', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes']\n",
        "cont_vars = ['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cUyVLqJeiBu"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for categorical variables\n",
        "for var in categ_vars:\n",
        "  print(f'Unique values in {var} are: {df[var].dropna().unique()})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEUXe8_Wfpkp"
      },
      "outputs": [],
      "source": [
        "# Checking the values for id\n",
        "print(f\"The number of unique IDs in dataset are {df['id'].nunique()}, with the minimum as {df['id'].min()} and maximum as {df['id'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gya0AVt1gVcO"
      },
      "source": [
        "It is observed that,\n",
        "*   **Sex** contains two values - Male and Female\n",
        "*   **Education** has 4 values - 1, 2, 3, 4. It is assumed that it represents a hierarchy of educational qualification levels among the patients\n",
        "*   **is_smoking**, **BPMeds**, **prevalentStroke**, **prevalentHyp** and **diabetes** are nominal binaries where 0 represents 'No' and 1 represents 'Yes'\n",
        "*   Each patient in the dataset are **unique** and there are no repeated data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#duplicate\n",
        "df.drop_duplicates(inplace=True)    # No duplicates were present"
      ],
      "metadata": {
        "id": "9Yt1ELY3epia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data wrangling was not performed in this project in this section now as the objective was to explore and analyze the raw data in its original form for now. This approach allowed for an authentic understanding of the dataset's inherent structure and characteristics, which was essential for meeting the goals."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style='darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "metadata": {
        "id": "57NS6ogyCTXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.histplot(df['age'],kde=True,color='skyblue')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand patient age spread ."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most patients are between 40 to 60 years old, indicating a middle-aged demographic."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.Helps target middle-aged adults for preventive care,\n",
        "Yes.Older population indicates rising CHD risk and healthcare costs."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.countplot(x='sex', data=df,palette='bright')\n",
        "plt.title('Male vs Female Distribution')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gender ratio influences disease prevelance."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slightly more females than males are present in the dataset."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.Supports gender-based health planning and resource allocation,\n",
        "Yes.Female dominance with slightly higher CHD risk could impact healthcare resource distribution."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "if 'education' in df.columns:\n",
        "    sns.countplot(x='education', data=df, palette='bright')\n",
        "    plt.title('Education Level Distribution')\n",
        "    plt.xlabel('Education Level')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Socio-economic status links to health awareness."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Majority of participants fall under lower education levels (levels 1 and 2)."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.Enables health education campaigns based on literacy levels,\n",
        "Yes.Low education levels correlate with poor health awareness and lifestyle habits."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "print(df.is_smoking.value_counts())\n",
        "sns.countplot(x='is_smoking', data=df, palette='pastel')\n",
        "plt.title('Smoking Status Distribution')\n",
        "plt.xlabel('Smoking Status')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smoking is a key cardiovascular risk."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a significant number of active smokers in the dataset."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Aids in designing anti-smoking health programs,\n",
        "Yes. High smoking rate signals increased long-term health issues."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.histplot(df['sysBP'],kde=True,color='orange')\n",
        "plt.title('Systolic Blood Pressure Distribution')\n",
        "plt.xlabel('Systolic BP')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BP is directly tied to heart disease."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many individuals show high-normal or elevated systolic blood presuure."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Promotes early intervention for blood pressure management,\n",
        "Yes. High prevalence of elevated BP indicates future chronic illness."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "sns.boxplot(x='TenYearCHD',y='age',data=df,palette='coolwarm')\n",
        "plt.title('Age vs TenYearCHD')\n",
        "plt.xticks([0,1],['No CHD','CHD'])\n",
        "plt.ylabel('Age')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out if age affects CHD risk."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHD-positive patients tend to be older than CHD-negative ones."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Justifies focused screening for older adults,\n",
        "Yes. Older CHD patients may reduce workforce productivity."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "sns.countplot(x='sex',hue='TenYearCHD',data=df, palette='Set1')\n",
        "plt.xticks([0,1],['Female','Male'])\n",
        "plt.title('Gender vs CHD Risk')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gender may correlate with heart disease."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Males show a slightly higher incidence of CHD compared to females."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Encourages gender-specific heart health strategies,\n",
        "Yes. Males show higher CHD risk, possibly impacting male labor force.\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "sns.boxplot(x='TenYearCHD',y='totChol',data=df,palette='Accent')\n",
        "plt.title('Total Cholesterol vs CHD')\n",
        "plt.xticks([0,1],['No CHD','CHD'])\n",
        "plt.ylabel('Total Cholesterol')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cholesterol is a classic risk factor."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHD patients have higher total cholesterol levels on average."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Validates the need for regular lipid screening,\n",
        "Yes. High cholesterol in CHD patients suggests long-term care dependency."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "sns.boxplot(x='TenYearCHD',y='glucose',data=df,palette='cubehelix')\n",
        "plt.title('Glucose Levels vs CHD')\n",
        "plt.xticks([0,1],['No CHD','CHD'])\n",
        "plt.ylabel('Glucose')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diabetes and CHD are related."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Glucose levels are slightly higher in CHD-positive individuals."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Supports dual screening for diabetes and heart disease,\n",
        "Yes. Elevated glucose in CHD group indicates risk of co-morbid conditions."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "sns.boxplot(x='TenYearCHD',y='heartRate',data=df,palette='cool')\n",
        "plt.title('Heart Rate vs CHD')\n",
        "plt.xticks([0,1],['No CHD','CHD'])\n",
        "plt.ylabel('Heart Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heart rate could indicate stress on the heart."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHD patients tend to have a slightly higher median heart rate."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Adds value in monitoring early stress or cardiac issues,\n",
        "No. Only slight difference; not a strong negative growth factor."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "sns.countplot(x='education',hue='is_smoking',data=df,palette='Set3')\n",
        "plt.title('Education vs Smoking Habits')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Education may relate to lifestyle habits."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower education levels are associated with higher smoking rates."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Enables targeted education-based smoking cessation programs,\n",
        "Yes. Lower education levels link to higher smoking, worsening long-term health."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Znh-vwooijZU"
      },
      "outputs": [],
      "source": [
        "# Function for Plotting the continuous variable distribution along with their median and mean\n",
        "def displot_with_median(dataset, variable, median = False, mean = False, unit = None):\n",
        "  '''A displot with median and mean and the appropriate units (if any) as the inputs'''\n",
        "  sns.displot(dataset[variable], height = 5, aspect = 11/6, bins = 40, kde = True)\n",
        "  if median == True:\n",
        "    plt.axvline(dataset[variable].median(), color = 'red', linestyle = '--', label = f'Median = {dataset[variable].median():.2f} {unit}')\n",
        "  if mean == True:\n",
        "    plt.axvline(dataset[variable].mean(), color = 'green', linestyle = '--', label = f'Mean = {dataset[variable].mean():.2f} {unit}')\n",
        "  plt.ylabel('Count of people')\n",
        "  plt.xlabel(var + f' ({unit})')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Units for each of the continuous variables\n",
        "units = ['years', 'count/day', 'mg/dL', 'mmHg', 'mmHg', 'kg/m2', 'beats/min', 'mg/dL']\n",
        "cont_var_units = dict(zip(cont_vars, units))\n",
        "\n",
        "# Plotting the continuous variable distributions\n",
        "for var in cont_var_units:\n",
        "  displot_with_median(df, var, median = True, mean = True, unit = cont_var_units[var])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpRgZoUfitTZ"
      },
      "source": [
        "The distplot is useful for continuous variables because it provides a visual representation of the distribution of values in the variable across the dataset. This allows one to understand how the data is distributed, such as whether it follows a normal distribution, is skewed to the left or right, or has multiple peaks. It can also help to identify outliers and anomalies in the data, which can be further investigated and addressed as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SkMQN_si2EH"
      },
      "source": [
        "* From the plots, most continuous variables appear to be right-skewed (tail towards higher values), as indicated by the median being less than the mean. Some variables show outliers that should be carefully checked to confirm if they are valid.\n",
        "\n",
        "* According to ACC/AHA guidelines, the optimal systolic and diastolic blood pressure levels are around 130 mmHg and 80 mmHg respectively. The median and mean blood pressure values in the dataset are close to or exceed these levels, suggesting that a majority of individuals may have elevated blood pressure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNnsiLmsJRLH"
      },
      "outputs": [],
      "source": [
        "# Defining a function to annotate the data values in the graph\n",
        "def display_vals(axis, round_ = 2):\n",
        "  '''Displays the data value on the chart'''\n",
        "  for p in axis.patches:\n",
        "   axis.annotate(str(round(p.get_height(), round_)), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwEgvrqtmSLO"
      },
      "outputs": [],
      "source": [
        "for var in categ_vars:\n",
        "  plt.figure(figsize = (11, 6))\n",
        "  ax = df[var].value_counts().plot(kind = 'bar')\n",
        "  plt.ylabel('Count of people')\n",
        "  plt.xlabel(var)\n",
        "  display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWKTeqMQmzu6"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "056MRcsemzu6"
      },
      "source": [
        "Barplots are useful for discrete variables because they allow us to visualize the frequency or proportion of each category in the variable occuring in the dataset, to identify any imbalances or patterns in the data, and for comparing these across different groups or subgroups in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1vPreDfm18Z"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuyHZwSZm18Z"
      },
      "source": [
        "The following can be observed from the above plots:\n",
        "*   There are **more number of females** present in the dataset than males.\n",
        "*   Assuming that the values in Education feature are hierarchical in ascending order, **more number of people are less educated** in the dataset\n",
        "*   **Only 100 people (~3% of dataset) are taking medications for Blood pressure** despite **over a 1000 people having history of Hypertension** and also, half of the people having systolic and diastolic Blood Pressure over the optimum 130mmHg/80mmHg respectively as seen in previous Chart\n",
        "*   **Only 22 people have had a recorded history of stroke** (0.6% of dataset)\n",
        "*   **Only 87 people have diabetes** (~2% of the dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bedNkrOkm4Ib"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afZwcIZpm4Ib"
      },
      "source": [
        "The disproportion between the number of people taking medications for Blood Pressure and those with BP levels higher than optimum could be addressed on analysing these data. Further tests if necessary could be conducted on those with high BP and not taking medications, and to prescribe them any medications based on the results, if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr=df.select_dtypes(include='number').corr()\n",
        "sns.heatmap(corr,annot=True,cmap='RdBu_r',fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understand relationships between all numerical variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age and systolic BP show notable correlation with CHD"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df[['age','sysBP','totChol','glucose','TenYearCHD']],hue='TenYearCHD',palette='husl')\n",
        "plt.suptitle('Pairplot of Key Features',y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visually compare relationships."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some separation between CHD and non-CHD groups is visible across variables."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R37pOE0mxs1U"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOgYE314xs1V"
      },
      "source": [
        "According to [Centers for DIsease Control and Prevention](https://www.cdc.gov/bloodpressure/facts.htm#:~:text=Nearly%20half%20of%20adults%20in,are%20taking%20medication%20for%20hypertension.), 44% of women have high blood pressure - defined as a Systolic BP higher than 130mmHg or Diastolic BP higher than 90mmHg - while 50% of men have the same. These 2 shall form the basis of the two Hypothesis tests in this section.\n",
        "\n",
        "The First Hypothesis Test is for:\n",
        "*   Null Hypothesis 1: 44% of women have high BP\n",
        "*   Alternate Hypothesis: Proportion of women having high BP is not equal to 44%\n",
        "\n",
        "The Second Hypothesis Test is for:\n",
        "*   Null Hypothesis 2: 50% of men have high BP\n",
        "*   Alternate Hypothesis: Proportion of men having high BP is not equal to 50%\n",
        "\n",
        "For this, the one-sample proportion test is used. The test is double tailed with significance value of 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9AZIaitxs1V"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOS0Q_7Mogg9"
      },
      "outputs": [],
      "source": [
        "# Performing the one-sample proportion tests\n",
        "h_vals = {'F':0.44, 'M':0.50}\n",
        "c = 1\n",
        "for sex in h_vals:\n",
        "  df_h1 = df[df['sex'] == sex]\n",
        "  n_sex = df_h1.shape[0]\n",
        "  n_sex_highbp = df_h1[(df_h1['sysBP'] >= 130) | (df_h1['diaBP'] >= 90)].shape[0]\n",
        "  alpha = 0.05\n",
        "  stat, p_value = proportions_ztest(count = n_sex_highbp, nobs = n_sex, value = h_vals[sex])\n",
        "  x = 'Women' if sex == 'F' else 'Men'\n",
        "  print(f'Hypothesis test {c}:')\n",
        "  if p_value < alpha:\n",
        "    print(f'P-value = {p_value} < {alpha}. The Null Hypothesis stands rejected. The true proportion of {x} having high Blood Pressure is greater than {h_vals[sex] * 100}%\\n')\n",
        "  else:\n",
        "    print(f'P-value = {p_value} > {alpha}. The Null Hypothesis that the true proportion of {x} with high Blood pressure is {h_vals[sex] * 100}% is failed to be rejected')\n",
        "  c+= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRblGZTfiRl4"
      },
      "source": [
        "It is to be noted that the Framingham test data is old, and older than the data provided in the link directing to Center for Disease Control, which is updated till the previous year. Hence, one of the tests (specifically, for the female) did not match up to the Null Hypothesis statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-J6AmMYxs1X"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWsY7XVPxs1Y"
      },
      "source": [
        "The **one-sample proportion test** is utilised for this statistical Hypothesis test. One-sample proportion test is used to determine if a proportion of a single sample differs significantly from a hypothesized value. It is also known as the one-sample z-test for proportions. This test is typically used to test a hypothesis about a population proportion based on a sample proportion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9adwgq1Zxs1Y"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "007n5v_6xs1Z"
      },
      "source": [
        "The test assumes that the sample is randomly selected and that the sample size is large enough to meet the conditions for a normal approximation of the sampling distribution, i.e., it is not necessary that the sample or population be normally distributed. The one-sample proportion test is used to test hypotheses about a single proportion or percentage, and it is based on the binomial distribution. Since the hypothesized values were for testing proportions, this particular test was utilised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJXiv31lixBb"
      },
      "source": [
        "This Hypothesis test will be based on the assumption that the median population will have the optimum values for Blood Pressure - i.e., 130/80 mmHg for the Systolic Blood Pressure and Diastolic Blood Pressure respectively. Thus, the Null Hypotheses will be on a metric which is a consolidation of these two metrics - the Mean Arterial Pressure (a weighted average of sys BP and dia BP).\n",
        "\n",
        "Thus, the optimal MAP taken for this test is (2*80 + 130)/3 = 96.667\n",
        "\n",
        "*   Null Hypothesis: Mean MAP of the population is 96.667mmHg\n",
        "*   Alternative Hypothesis: Mean MAP of the population is not equal to 96.667mmHg\n",
        "\n",
        "Test summary:\n",
        "*   The one-sample t-test will be used\n",
        "*   The test is two-tailed with a significance value of 0.05\n",
        "*   Since the t-test is used, it is required that the data is normally distributed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHu7zqiftfiT"
      },
      "outputs": [],
      "source": [
        "df_h2 = df[['sysBP', 'diaBP']]\n",
        "df_h2['MAP'] = (df['sysBP'] + df['diaBP'] * 2)/3\n",
        "h2_val = 96.667\n",
        "alpha2 = 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KFDI4bll9Mx"
      },
      "source": [
        "The Shapiro test shall be used to check the normal distribution of the MAP feature with a significance value of 0.05, since normal distribution is a requirement for this test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHUaGh3PlDI7"
      },
      "outputs": [],
      "source": [
        "print(f\"P-value for checking Normal distribution using shapiro test = {shapiro(df_h2['MAP'])[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkIKd_YUmeiu"
      },
      "outputs": [],
      "source": [
        "var = 'MAP'\n",
        "displot_with_median(df_h2, var, median = True, mean = True, unit = 'mmHg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZfcWSRdl3_D"
      },
      "source": [
        "Since this p-value is very low, we fail to reject the Null Hypothesis that the data is normally distributed, and the data has to be transformed to make it normally distributed. The inverse transform is used since the data has a left skew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4Qw57iQm2G9"
      },
      "outputs": [],
      "source": [
        "df_h2['MAP'] = 1/df_h2['MAP']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZGw7ZwzmN3n"
      },
      "outputs": [],
      "source": [
        "print(f\"p value for checking Normal distribution using shapiro test = {shapiro(df_h2['MAP'])[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CerHO8LqnCfD"
      },
      "outputs": [],
      "source": [
        "var = 'MAP'\n",
        "displot_with_median(df_h2, var, median = True, mean = True, unit = '1/(mmHg)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L27SiwPnAZc"
      },
      "source": [
        "Now that the data is normally distributed, with a p-value from the shapiro test greater than a required significance value, the requirement for the t-test is fulfilled. The Null Hypothesis value of MAP also has to be applied this inverse transformation to maintain consistency. The t-test is applied in the below code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma4qXxJgn6Q9"
      },
      "outputs": [],
      "source": [
        "p_value_h2 = ttest_1samp(a = df_h2['MAP'], popmean = 1/h2_val)[1]\n",
        "if p_value_h2 < alpha2:\n",
        "  print(f'P-value = {p_value_h2} < {alpha2}. The Null Hypothesis stands rejected. The true mean of Mean Arterial Pressure is not equal to the optimum {h2_val}mmHg')\n",
        "else:\n",
        "  print(f'P-value = {p_value_h2} > {alpha2}. The Null Hypothesis that the true mean of Mean Arterial Pressure is equal to {h2_val}mmHg is failed to be rejected')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tqGbqsPp94s"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC49W2Qgp-6E"
      },
      "source": [
        "Two statistical tests were applied in this Hypothesis test:\n",
        "*   **Shapiro test** to check whether the MAP values are normally distributed\n",
        "*   **One-sample t-test** to check whether the true mean of the MAP was indeed equal to the Hypothesised value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK4dROzuqTx8"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBizy6dDqUhh"
      },
      "source": [
        "The one-sample t-test is used here for the following reasons:\n",
        "*  The goal was to check the hypothesis statement about the true mean of a metric\n",
        "*  The Population variance of the same metric (MAP) was not known\n",
        "\n",
        "In such a case, the t-test is usually relied on.\n",
        "\n",
        "Also, it is necessary that the data be normally distributed in order to apply a t-test on it. Hence, the Shapiro test was utilised to check whether the data is normally distributed, and if not, to apply the relevant transformations to make it normally distributed for the one-sample t-test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "fgwTeHC70UlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): The average age of patients with CHD is equal to those without CHD.\n",
        "\n",
        "Alternative Hypothesis (H₁): The average age of patients with CHD is significantly higher than those without CHD.\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "# Split age data into CHD and non-CHD groups\n",
        "age_chd = df[df['TenYearCHD'] == 1]['age']\n",
        "age_no_chd = df[df['TenYearCHD'] == 0]['age']\n",
        "# Perform two-sample t-test\n",
        "t_stat, p_value = ttest_ind(age_chd, age_no_chd, nan_policy='omit')\n",
        "print(\"P-Value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent Two-Sample t-test."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are comparing the average age between two independent groups (CHD vs non-CHD)."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr7fn4QAvrrP"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC6tXygGwDXC"
      },
      "outputs": [],
      "source": [
        "# Creating a copy of the data\n",
        "data = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVQCAY80vrrY"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk5eyN8ZvrrY"
      },
      "outputs": [],
      "source": [
        "print(f'There is a total of {df.isna().sum().sum()} missing values in the dataset. They are distributed among the variables as follows\\n')\n",
        "\n",
        "# Defining a function to annotate the data values in the graph\n",
        "def display_vals(axis, round_ = 2):\n",
        "  '''Displays the data value on the chart'''\n",
        "  for p in axis.patches:\n",
        "   axis.annotate(str(round(p.get_height(), round_)), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "\n",
        "# Visualising the number of missing values in each variable\n",
        "plt.figure(figsize = (11, 6))\n",
        "ax = data.isna().sum().sort_values(ascending = False).plot(kind = 'bar')\n",
        "plt.ylabel('Number of missing values')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tety32d1y-6X"
      },
      "source": [
        "#### 1.1 Categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_lW-u9s0A9X"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (11, 6))\n",
        "ax = data[categ_vars].isna().sum().sort_values(ascending = False).plot(kind = 'bar')\n",
        "plt.ylabel('Number of missing values')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqspvfGMzI4X"
      },
      "source": [
        "Among the categorical variables, the **education** variable has been concluded to be dropped from the dataset. So, only **BPMeds** among the categorical variables contain missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA-U0aGgzxbC"
      },
      "outputs": [],
      "source": [
        "categ_vars.remove('education')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYV8zbZM_Xhp"
      },
      "outputs": [],
      "source": [
        "# Collecting the indices of rows where BPMeds is missing\n",
        "bpmeds_missing = data[data['BPMeds'].isna()].index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1g5IPqcH76p"
      },
      "source": [
        "[According to this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2560868/#:~:text=For%20most%20people%2C%20blood%20pressure%20readings%20should%20be,80%20mmHg%20when%20measured%20in%20the%20doctor%E2%80%99s%20office.) from the National Library of Medicine, BP medications are recommended by doctors to the following patients:\n",
        "*   Having systolic and diastolic Blood Pressure levels above 140/90 mmHg\n",
        "*   For those having diabetes or kidney diseases, having Blood pressure levels above 130/80 mmHg\n",
        "\n",
        "Hence, the missing values in BPMeds, which are not large in number (1.2% of dataset), are filled with the above rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NOP9aAsAe2j"
      },
      "outputs": [],
      "source": [
        "# Filling the BPMeds missing values as according to above\n",
        "for indx in bpmeds_missing:\n",
        "  # For diabetic patients\n",
        "  if data.loc[indx, 'diabetes'] == 1 and (data.loc[indx, 'sysBP'] > 130 or data.loc[indx, 'diaBP'] > 80):\n",
        "    data.loc[indx, 'BPMeds'] = 1\n",
        "\n",
        "  # For non-diabetic patients\n",
        "  elif data.loc[indx, 'diabetes'] == 0 and (data.loc[indx, 'sysBP'] > 140 or data.loc[indx, 'diaBP'] > 90):\n",
        "    data.loc[indx, 'BPMeds'] = 1\n",
        "\n",
        "  # For rest of the patients\n",
        "  else:\n",
        "    data.loc[indx, 'BPMeds'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiO5b7toCoHk"
      },
      "outputs": [],
      "source": [
        "data[categ_vars].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaSXBUyu4JOo"
      },
      "source": [
        "All missing values from categorical variables have been removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoWXapGDcUY"
      },
      "source": [
        "#### 1.2 Continuous variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pnoyBD5Dgk_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (11, 6))\n",
        "ax = data[cont_vars].isna().sum().sort_values(ascending = False).plot(kind = 'bar')\n",
        "plt.ylabel('Number of missing values')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bREyQhpn4lMH"
      },
      "source": [
        "For continuous variabes, **cigsPerDay** will be dealt with separately before handling the other variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_o2Fi1Kb1y"
      },
      "source": [
        "##### 1.2.1 cigsPerDay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX151NpX5aHV"
      },
      "source": [
        "Let us take a brief look at the relation between **cigsPerDay** and **is_smoking** (current smoker or not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STjGaU9lK8_G"
      },
      "outputs": [],
      "source": [
        "# Checking unique values for cigsPerDay when is_smoking = \"NO\"\n",
        "data[data['is_smoking'] == 'NO']['cigsPerDay'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4ioLu_QLEsc"
      },
      "outputs": [],
      "source": [
        "# Checking unique values for cigsPerDay when is_smoking = \"YES\"\n",
        "data[data['is_smoking'] == 'YES']['cigsPerDay'].value_counts().sort_index().head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zToeV0Pj6_-h"
      },
      "outputs": [],
      "source": [
        "# Checking values for is_smoking wherever cigsPerDay has a missing value\n",
        "data[data['cigsPerDay'].isna()]['is_smoking'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvRCbTJq6fCp"
      },
      "outputs": [],
      "source": [
        "# Checking the distribution\n",
        "var = 'cigsPerDay'\n",
        "displot_with_median(data, var, median = True, mean = True, unit = cont_var_units[var])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQOiHU1t5olz"
      },
      "source": [
        "*   As can be observed, wherever **is_smoking = 'NO'**, the value of **cigsPerDay** is always **0**. **cigsPerDay** is never zero when **is_smoking = 'YES'**. Hence, a one-to-one mapped relationship exists between **is_smoking = 'NO'** and **cigsPerDay = 0**.\n",
        "*   All the people where **cigsPerDay** has a missing value are current smokers (i.e., **is_smoking == 'YES'**)\n",
        "*   Also, the distribution of **cigsPerDay** is extremely left skewed with a median of 0, indicating highest amount of non-smokers in the dataset\n",
        "\n",
        "From the above observations, it would not make sense to impute the missing values for **cigsPerDay** with the median of the entire dataset. **Instead, median/mean of only the current smokers is more appropriate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkV_heaZ6OiC"
      },
      "outputs": [],
      "source": [
        "# Checking distribution and outliers for only smokers\n",
        "var = 'cigsPerDay'\n",
        "fig, axx = plt.subplots(nrows = 1, ncols = 2, figsize = (16, 6))\n",
        "sns.histplot(data[data['is_smoking'] == 'YES'][var], bins = 40, kde = True, ax = axx[0])\n",
        "sns.boxplot(data[data['is_smoking'] == 'YES'], x = var, orient = 'h', ax = axx[1])\n",
        "axx[1].set(ylabel = var, xlabel = cont_var_units[var])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v0KH6VN9SjK"
      },
      "source": [
        "**Since cigsPerDay contains outliers even among the smokers in the dataset, the median is chosen for imputation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRuofE3I9h54"
      },
      "outputs": [],
      "source": [
        "# Imputing with median of current smokers\n",
        "imputing_median1 = data[data['is_smoking'] == 'YES']['cigsPerDay'].median()\n",
        "data['cigsPerDay'] = data['cigsPerDay'].fillna(imputing_median1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk_2Xbsn98vD"
      },
      "outputs": [],
      "source": [
        "# Checking if any missing values are still present\n",
        "data['cigsPerDay'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps5rlOtO-fvq"
      },
      "source": [
        "##### 1.2.2 glucose, totChol, BMI and heartRate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgNVnXUjNg-p"
      },
      "outputs": [],
      "source": [
        "# Checking distribution and outliers\n",
        "for var in ['glucose', 'totChol', 'BMI', 'heartRate']:\n",
        "  fig, axx = plt.subplots(nrows = 1, ncols = 2, figsize = (16, 6))\n",
        "  sns.histplot(data[var], bins = 40, kde = True, ax = axx[0])\n",
        "  axx[0].axvline(df[var].median(), color = 'red', linestyle = '--', label = f'Median = {round(df[var].median(), 2)}')\n",
        "  axx[0].axvline(df[var].mean(), color = 'green', linestyle = '--', label = f'Mean = {round(df[var].mean(), 2)}')\n",
        "  axx[0].set(xlabel = var + f' ({cont_var_units[var]})')\n",
        "  axx[0].legend()\n",
        "  sns.boxplot(data, x = var, orient = 'h', ax = axx[1])\n",
        "  axx[1].set(ylabel = var, xlabel = cont_var_units[var])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_lWdria_p30"
      },
      "source": [
        "As observed from above,\n",
        "*   The mean of each variable is slightly higher than the median indicating a right skew of varying degrees.\n",
        "*   Each variable contains outliers even outside of twice the interquartile range.\n",
        "\n",
        "For these reasons, missing values in each variable is imputed with the median of the respective variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "basLcfRGAMPX"
      },
      "outputs": [],
      "source": [
        "# Imputing the missing values with the median for each variable\n",
        "for var in ['glucose', 'totChol', 'BMI', 'heartRate']:\n",
        "  imputing_median = data[var].median()\n",
        "  data[var]  = data[var].fillna(imputing_median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L2dvYgMBf2h"
      },
      "outputs": [],
      "source": [
        "# Checking for any missing values in the dataset\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFGsIKn7Bmln"
      },
      "source": [
        "All missing values have been removed except education which is going to be dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.3 Checking mean, median and distribution of continuous variables after imputing missing values"
      ],
      "metadata": {
        "id": "BtY0DZ3L9ZLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in ['cigsPerDay', 'glucose', 'totChol', 'BMI', 'heartRate']:\n",
        "  fig, axx = plt.subplots(nrows = 1, ncols = 2, figsize = (16, 6))\n",
        "  sns.histplot(df[var], bins = 40, kde = True, ax = axx[0])\n",
        "  sns.histplot(data[var], bins = 40, kde = True, ax = axx[1])\n",
        "  for i, datas in enumerate([df, data]):\n",
        "    axx[i].axvline(datas[var].median(), color = 'red', linestyle = '--', label = f'Median = {datas[var].median():.2f} {cont_var_units[var]}')\n",
        "    axx[i].axvline(datas[var].mean(), color = 'green', linestyle = '--', label = f'Mean = {datas[var].mean():.2f} {cont_var_units[var]}')\n",
        "    axx[i].set(xlabel = var + f' ({cont_var_units[var]})', ylabel = 'Count of people')\n",
        "    axx[i].legend()\n",
        "  axx[0].set(title = f'Input distribution of {var}')\n",
        "  axx[1].set(title = f'Distribution of {var} after imputing null values')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "n62b2rRp9jGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that the mean, median and the overall distribution for each of the continuous variables are the same before and after imputation of missing values."
      ],
      "metadata": {
        "id": "9coz3u4n-g3W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aosFJnICG-R"
      },
      "source": [
        "### 2. Feature Manipulation and Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppvgX3lNKwxs"
      },
      "source": [
        "Before analysing outliers, certain features need to be handled to reduce dimensionality . In this section, the redundant variables are removed and features with high correlation are dealt with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvGi0VGEGmP6"
      },
      "source": [
        "#### 2.1 education, is_smoking and prevalentStroke"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-2N12U8CLm1"
      },
      "source": [
        "Right off the start, **education** and **is_smoking** can be removed from the dataset.\n",
        "\n",
        "*   **Education** is removed because of the less information provided of the variable, and the low correlation with **TenYearCHD**.\n",
        "*   **is_smoking** is removed because of the redundancy of information with respect to **cigsPerDay**. All the information contained within the former is already found in the latter, i.e., whenever **is_smoking = NO**, **cigsPerDay** has a value of zero, and whenever **is_smoking = YES**, **cigsPerDay** has a non-zero value ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBOG5BNMEuUz"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['education', 'is_smoking'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exxHkW2A-mQg"
      },
      "source": [
        "Also, **prevalentStroke** is removed because of the high class imbalance - only 0.5% of the dataset having one class, as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT-OXhkE-sUd"
      },
      "outputs": [],
      "source": [
        "var = 'prevalentStroke'\n",
        "plt.figure(figsize = (11, 6))\n",
        "ax = data[var].value_counts().plot(kind = 'bar')\n",
        "plt.ylabel('Count of people')\n",
        "plt.xlabel(var)\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MStyiS5p_Et-"
      },
      "outputs": [],
      "source": [
        "data.drop('prevalentStroke', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKRlAKPJm7eg"
      },
      "source": [
        "#### 2.2 Systolic BP and Diastolic BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6R42R7VE9U2"
      },
      "source": [
        "*   Now, to address the high multicollinearity between systolic Blood Pressure and Diastolic Blood pressure, the two are combined to form another continuous variable named '**Mean Arterial Pressure**'\n",
        "*   The Mean Arterial Pressure is a weighted average of diastolic and systolic Blood Pressures representing the average arterial pressure in one cardiac cycle. The formula is given as\n",
        "\n",
        "\\begin{align}\n",
        "MAP = \\frac{2*DiastolicBP + Systolic BP} 3\n",
        "\\end{align}\n",
        "\n",
        "*   The MAP is a better predictor of Cardiovascular disease than Pulse Pressure, which is the other variable combining the systolic and diastolic Blood Pressures. Hence, the MAP is chosen to resolve the multicollinearity between **sysBP and diaBP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly_DH8PZHPgC"
      },
      "outputs": [],
      "source": [
        "data['MAP'] = (data['sysBP'] + 2*data['diaBP'])/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBDXpbNwSqDl"
      },
      "outputs": [],
      "source": [
        "# Checking the distribution\n",
        "displot_with_median(dataset = data, variable = 'MAP', median = True, mean = True, unit = 'mmHg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLcEsY8b_REH"
      },
      "source": [
        "#### 2.3 prevalentHyp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aptnf2gYOC7Y"
      },
      "outputs": [],
      "source": [
        "# Checking distribution of prevalentHyp\n",
        "\n",
        "filter_counts = data[data['MAP'] > 100]['prevalentHyp'].value_counts().sort_index()\n",
        "all_counts = data['prevalentHyp'].value_counts().sort_index()\n",
        "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6))\n",
        "ax[0].bar(all_counts.index, all_counts.values)\n",
        "ax[0].set_title('All Data')\n",
        "ax[1].bar(filter_counts.index, filter_counts.values)\n",
        "ax[1].set_title('MAP > 100mmHg')\n",
        "for i in range(2):\n",
        "  ax[i].set(xticks = [0, 1], ylim = [0, 2500], ylabel = 'Count of people', xlabel = 'prevalentHyp')\n",
        "  display_vals(ax[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pointbiserialr\n",
        "corr, p_value = pointbiserialr(data['prevalentHyp'], data['MAP'])\n",
        "print(f\"Point biserial correlation: {corr}, p-value: {p_value}\")\n",
        "\n",
        "\n",
        "print()\n",
        "correlation = data[['prevalentHyp', 'MAP']].corr()\n",
        "print(correlation)\n",
        "\n"
      ],
      "metadata": {
        "id": "3yiaKzD5q_BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A correlation of ~0.69 or higher suggests moderate to strong linear relationship.\n",
        "\n",
        "\n",
        "*   correlation is high and statistically significant (p-value < 0.05)\n",
        "*   **prevalentHyp** is deemed redundant and dropped from the analysis"
      ],
      "metadata": {
        "id": "Fa8wo039qM_D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktBEqvDJxvbc"
      },
      "source": [
        "#### 2.4 Glucose and Diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7sOxPJWNwQE"
      },
      "source": [
        "*   **Glucose and diabetes** are directly linked to each other in that, high levels of glucose indicate high likelihood of diabetes. While there are other factors which cause elevated glucose levels even for non-diabetic patients, like stress, certain medications, and some medical conditions, it is not common.\n",
        "*    An analysis between the relationship of glucose and diabetes in this dataset is conducted based on the above factors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pointbiserialr\n",
        "\n",
        "corr, p_value = pointbiserialr(data['diabetes'], data['glucose'])\n",
        "print(f\"Point Biserial Correlation: {corr:.3f}, p-value: {p_value:.3e}\")\n"
      ],
      "metadata": {
        "id": "pVNcei2VtTCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C3I6r4w22bJ"
      },
      "source": [
        "The diabetes column can be dropped as it is redundant, given its high correlation with glucose. This suggests that glucose alone provides similar predictive information.\n",
        "\n",
        "The glucose variable contains a large number of outliers, which will be handled by transforming it into a categorical variable called diabetes_grade, enabling more robust analysis and modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8AW2bb-5ggX"
      },
      "outputs": [],
      "source": [
        "# Defining the function for Diabetes grades\n",
        "def diabetes_grades(df):\n",
        "  if df['glucose'] >= 126:\n",
        "    return 4 #Diabetes\n",
        "  elif df['glucose'] > 100:\n",
        "    return 3 #Pre-diabetes\n",
        "  elif df['glucose'] > 70:\n",
        "    return 2 #Normal\n",
        "  elif df['glucose'] < 71:\n",
        "    return 1 #Hypoglycemia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAKtUPu59dIb"
      },
      "outputs": [],
      "source": [
        "data['diabetes_grade'] = data.apply(diabetes_grades, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoMqPmIeCk_0"
      },
      "source": [
        "#### 2.6 Final features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2YIduFc9qbN"
      },
      "outputs": [],
      "source": [
        "# Dropping the redundant columns\n",
        "data = data.drop(['sysBP', 'diaBP', 'glucose', 'diabetes', 'prevalentHyp'], axis = 1)\n",
        "cont_vars = [var for var in cont_vars if var not in ['sysBP', 'diaBP', 'glucose']]\n",
        "cont_vars+=['MAP']\n",
        "categ_vars = [var for var in categ_vars if var not in ['is_smoking', 'diabetes', 'prevalentStroke', 'prevalentHyp']]\n",
        "categ_vars+=['diabetes_grade']\n",
        "\n",
        "print(f'The categorical variables are: {categ_vars}')\n",
        "print(f'The continuous variables are: {cont_vars}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OItS_O3jWSlj"
      },
      "outputs": [],
      "source": [
        "# Checking the correlation between variables\n",
        "corr=data.select_dtypes(include='number').corr()\n",
        "sns.heatmap(corr,annot=True,cmap='RdBu_r',fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-BmYUSiWjLy"
      },
      "source": [
        "As can be seen above, all multicollinearity has been removed ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf5xSBDwCvnH"
      },
      "source": [
        "In summary, this section consisted of:\n",
        "*   dropping **education**, **is_smoking** and **prevalentStroke**\n",
        "*   combining **sysBP** and **diaBP** to get **MAP**\n",
        "*   modifying **glucose** to get **diabetes_grade**\n",
        "*   dropping **diabetes** and **prevaletHyp**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiwA55aFvrrj"
      },
      "source": [
        "### 3. Handling Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iczhTQKYCNW"
      },
      "source": [
        "*   It is important to note that while outliers may impact the accuracy of the model, they have to be dealt with carefully as some outliers may be realistic and within the possible range of values of the particular feature, and not due to any measurement error.\n",
        "*   At the same time, extreme outliers even if they are possible and true values, do need to be dealt with as it impacts the predictive power of the Machine Learning model which is sensitive to outliers.\n",
        "*   Since many continuous variables have a positive correlation with the dependent variable **TenYearCHD**, a bivariate outlier analysis has to be done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk4hzCaWvrrk"
      },
      "outputs": [],
      "source": [
        "# Visualising the outliers\n",
        "cont_var_units['MAP'] = 'mmHg'\n",
        "for var in cont_vars:\n",
        "  plt.figure(figsize = (13,7))\n",
        "  sns.boxplot(data = data, y = var, x = 'TenYearCHD')\n",
        "  plt.ylabel(var)\n",
        "  plt.xlabel(cont_var_units[var])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi78avv9ewHw"
      },
      "source": [
        "*   It can be observed that\n",
        "  *   **age** has no outliers\n",
        "  *   **cigsPerDay** has outliers of about **60 and 70 cigs/day**\n",
        "  *   **totChol** has outliers with maximum of around **700mg/dL**, and minimum around **100mg/dL**\n",
        "  *   There are patients with **BMI** even above **50**\n",
        "  *   **heartRate** has outliers with maximum of around **140 beats/day**, and with minimum below **50 beats/day**\n",
        "  *   **MAP** also has outliers with maximum values close to **190mmHg**\n",
        "  \n",
        "*   All these figures are within the possible range of values for each respective feature. But even if they're realistic, they are extremely rare and this may affect the model prediction power\n",
        "*   Since they are within the possible range of values, the outliers shall not be trimmed since that may lead to loss of data and make the ML models biased. Instead, they shall be limited to a particular value, which though are less likely to occur are not as rare as the maximum outliers. This process is called **Winsorising**.\n",
        "  *   **cigsPerDay** shall be limited to **50 cigs/day**\n",
        "  *   **totChol - 500mg/dL**\n",
        "  *   **BMI - 45 (>45 is extremely obese)**\n",
        "  *   **heartRate** in the range of **50-120 beats/day**\n",
        "  *   **MAP - 165mmHg**, beyond which it is a medical emergency\n",
        "  *   **NOTE**: **Cholestrol level, MAP and heartRate** above **500mg/dL, 120beats/day and 165mmHg** respectively are considered medical emergencies and require immediate medical attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thX6QPSLgG_9"
      },
      "outputs": [],
      "source": [
        "# Limitting maximum values\n",
        "max_limits = [50, 500, 45, 120, 165]\n",
        "outlier_vars = cont_vars[1:]\n",
        "for var, limit in zip(outlier_vars, max_limits):\n",
        "  data.loc[data[var] > limit, var] = limit\n",
        "\n",
        "# Limitting the minimum value of heartRate\n",
        "data.loc[data['heartRate'] < 50, 'heartRate'] = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpKjyHou_5WR"
      },
      "outputs": [],
      "source": [
        "# Visualising the outliers with the maximum limit after Winsorising\n",
        "for var, limit in zip(outlier_vars, max_limits):\n",
        "  plt.figure(figsize = (13,7))\n",
        "  sns.boxplot(data = data, y = var, x = 'TenYearCHD')\n",
        "  plt.axhline(limit, color = 'red', linestyle = '--')\n",
        "  plt.ylabel(var)\n",
        "  plt.xlabel(cont_var_units[var])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsX4i7EJAhgm"
      },
      "source": [
        "All the datapoints for each variable have now been contained within the chosen limits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR1jqWUvvrrl"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "As stated earlier, **Winsorising** was used to handle the outliers in this dataset. Winsorizing is preferred over Trimming when the number of outliers is small, and the range of values is not unrealistically extreme. Winsorising replaces the extreme values with a value within the range of the data, which preserves the original distribution of the data. In contrast, trimming completely removes the extreme values from the data, which can alter the distribution of the data. Since the datapoints here were not outside of the possible range of each feature, and were not large in number, Winsorising was used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-8XhUwVvrrl"
      },
      "source": [
        "### 4. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxmt23CEZhnG"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN73tgTRCIE_"
      },
      "outputs": [],
      "source": [
        "data['sex'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVx8gl4fZmhJ"
      },
      "source": [
        "As seen from above, **sex** is still of object type. Since there are only 2 classes, this feature is encoded as per the following rule\n",
        "*   **Male - 1**\n",
        "*   **Female - 0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zba56lc5vrro"
      },
      "outputs": [],
      "source": [
        "# Encoding sex column\n",
        "data['sex'] = data['sex'].map({'M':1, 'F':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7AxziciZ1kB"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbfhwDTqBvtb"
      },
      "source": [
        "All variables are now in numerical datatype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwtAqn7nvrro"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Z6b6invrrp"
      },
      "source": [
        "One-Hot Encoding was used here since the sex variable had only 2 classes. Essentially, what this feature represents is whether a patient is male or not by assigning a non-zero value (one) if it is male."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HLImntrvrrp"
      },
      "source": [
        "### 5. Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcTWwjXwhRy1"
      },
      "source": [
        "In this case, data is not transformed because outliers were handled without the need to change the data distributions. So, the splitting of the data is directly performed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRQaGa0Mvrrp"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['TenYearCHD', 'id'], axis = 1)\n",
        "Y = data['TenYearCHD']\n",
        "\n",
        "# Visualising the input data\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az1ESZ3gmXvN"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 8, stratify = Y, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKHn5Q3doyjm"
      },
      "outputs": [],
      "source": [
        "Y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tH_ErDLo1ZI"
      },
      "outputs": [],
      "source": [
        "Y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZJHh6W-vrrq"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqDA1hmyvrrq"
      },
      "source": [
        "Because there is not a large number of data, and with 9 independent input features, a larger train-test split of 80-20 is chosen to allow the model to learn from a more diverse set of examples. Since it is an unbalanced problem, the split is stratified with respect to the dependent variable **TenYearCHD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bgVo0bcvrrq"
      },
      "source": [
        "### 6. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igf-x7ugvrrq"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIkMvJzNvrrq"
      },
      "source": [
        "Yes, the dataset is imbalanced since the classes in the variable to be predicted are not equally distributed. There are more number of people who do not have a risk of CHD compared to those who do. This can be seen in the below plot of the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvHfLW0zpWxc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (11, 6))\n",
        "ax = Y_train.value_counts().plot(kind = 'bar')\n",
        "plt.ylabel('Count of people')\n",
        "plt.xlabel('TenYearCHD')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I40S1wCJvrrq"
      },
      "outputs": [],
      "source": [
        "# Handling Imbalanced Dataset\n",
        "smote = SMOTE(random_state = 8)\n",
        "X_smote, Y_train_final = smote.fit_resample(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS1cp95qpvbR"
      },
      "outputs": [],
      "source": [
        "# Visualising the class balance after using SMOTE\n",
        "plt.figure(figsize = (11, 6))\n",
        "ax = Y_train_final.value_counts().plot(kind = 'bar')\n",
        "plt.ylabel('Count of people')\n",
        "plt.xlabel('TenYearCHD')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWDf5vqrvrrr"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvH1iCa4vrrr"
      },
      "source": [
        "Synthetic Minority Over-sampling Technique (SMOTE) is a popular oversampling method for handling class imbalance. It is used for the following reasons\n",
        "*   Since not much data is present for training, undersampling will not be a good method as it may lead to loss of data and hence leading to underfitting of the model\n",
        "*   Also, because there is a large imbalance (82-18% imbalance) simply replicating minority class values to create a balanced dataset will lead to overfitting of the model\n",
        "*   Instead, SMOTE is used which synthetically creates new datapoints using the k-nearest neighbours, hence creating new realistic data to train the models on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLZq4RLpvrrr"
      },
      "source": [
        "### 7. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUxTY1lfvrrr"
      },
      "outputs": [],
      "source": [
        "# Scaling the train and test data according to train data\n",
        "scaler = MinMaxScaler()\n",
        "X_train_final = scaler.fit_transform(X_smote)\n",
        "X_test_final = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAnNOkYCvrrr"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl5Pk5X1n-cn"
      },
      "source": [
        "*   The Minmaxscaler is usually used when the lower and upper boundaries in the area of interest are well-known\n",
        "*   It also helps to maintain the the interpretability of the values after scaling\n",
        "*   MinMaxScaler also helps maintain the relative relationship between the datapoints, which is crucial in this case of CHD risk prediction\n",
        "*   Also since there is no specific requirement of the mean and standard deviation of the data, the MinMaxScaler is used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnCzSbEmv50I"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hchcuKgJUcqc"
      },
      "source": [
        "The following 3 models are implemented in this section on the train dataset, and then tested on the test data.\n",
        "*   Logistic Regression\n",
        "*   Decision Tree\n",
        "*   XGBoost\n",
        "\n",
        "The scoring metric preferred for evaluation is the **Recall**. The **ROC-AUC score** is also recorded for each model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLIjy_TPVqu"
      },
      "source": [
        "### Functions to train each ML Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuyokYvhX2L1"
      },
      "outputs": [],
      "source": [
        "# Function to plot the Confusion Matrix\n",
        "def confusion_plot(cm):\n",
        "  '''Plots the Confusion Matrix given as input'''\n",
        "  cmd = ConfusionMatrixDisplay(cm, display_labels = ['No risk (0)', 'Risk (1)'])\n",
        "  cmd.plot(cmap = 'Blues')\n",
        "  plt.title('Confusion Matrix for Test Data')\n",
        "  plt.show()\n",
        "\n",
        "# Function to train and test a given classification model\n",
        "def model_train_test(model, train_x, train_y, test_x, test_y, gs = False, confusion = True):\n",
        "  '''Trains the classification model given as input. Other inputs include Test and train data\n",
        "  and a Boolean to inform the function if GridSearch is being performed\n",
        "  Returns the train and test Recalls and ROC-AUC scores, the test data predictions, and the final model'''\n",
        "\n",
        "  model.fit(train_x, train_y)\n",
        "  if gs == True:\n",
        "    print(f'Best model parameters are: {model.best_params_}')\n",
        "    print(f'Best model score is: {model.best_score_}\\n')\n",
        "    model = model.best_estimator_\n",
        "\n",
        "  # Getting the train and test predictions\n",
        "  train_preds = model.predict(train_x)\n",
        "  train_recall = recall_score(y_true = train_y, y_pred = train_preds, average='binary')\n",
        "  train_roc = roc_auc_score(train_y, train_preds)\n",
        "  test_preds = model.predict(test_x)\n",
        "  test_recall = recall_score(y_true = test_y, y_pred = test_preds, average='binary')\n",
        "  test_roc = roc_auc_score(test_y, test_preds)\n",
        "\n",
        "  # Plotting confusion matrix\n",
        "  if confusion == True:\n",
        "    confusion_plot(confusion_matrix(test_y, test_preds))\n",
        "\n",
        "  output_metrics = {'Train Recall':train_recall, 'Test Recall':test_recall, 'Train ROC-AUC':train_roc, 'Test ROC-AUC':test_roc}\n",
        "  return output_metrics, test_preds, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT4SzcnhlYOC"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary of lists to store Train and test Recalls and ROC-AUC scores\n",
        "scores = dict()\n",
        "scores['Train Recall'] = []\n",
        "scores['Test Recall'] = []\n",
        "scores['Train ROC-AUC'] = []\n",
        "scores['Test ROC-AUC'] = []\n",
        "model_names = ['Logistic Regression', 'XGBoost' ,'Decision Tree']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgQ4qwHv50K"
      },
      "source": [
        "### ML Model - 1 - Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "lr_scores, lr_test_preds, lr_model = model_train_test(LogisticRegression(), X_train_final, Y_train_final, X_test_final, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLxZ-dvJjhDa"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(classification_report(Y_test, lr_test_preds, target_names=['class-0', 'class-1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-UM4Jh6j-Ai"
      },
      "outputs": [],
      "source": [
        "# Printing the train and test Recalls and ROC-AUC scores\n",
        "def print_scores(model_name, model_scores):\n",
        "  '''Function to print the scores of a given model'''\n",
        "  print(f\"The train and test recalls of the {model_name} Model are: {round(model_scores['Train Recall'] * 100, 2)}% and {round(model_scores['Test Recall'] * 100, 2)}% respectively\")\n",
        "  print(f\"The train and test ROC-AUC scores of the {model_name} Model are: {round(model_scores['Train ROC-AUC'] * 100, 2)}% and {round(model_scores['Test ROC-AUC'] * 100, 2)}% respectively\")\n",
        "\n",
        "print_scores(model_name = model_names[0], model_scores = lr_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEi846Bm7dQJ"
      },
      "outputs": [],
      "source": [
        "# Displaying feature importances\n",
        "lr_importances = pd.Series(abs(lr_model.coef_[0]), index = X.columns)\n",
        "plt.figure(figsize = (11, 6))\n",
        "ax = lr_importances.sort_values(ascending = False).plot(kind = 'bar')\n",
        "ax.set(xlabel = 'Features', ylabel = 'Feature importances')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nIuHCDbCpBu"
      },
      "source": [
        "The following results can be observed from the Logistic Regression model:\n",
        "*   **Train recall of 66.78% and Test Recall of 69.6%**\n",
        "*   **Train ROC-AUC score of 65.85% and Test Recall of 68.83%**\n",
        "  *   A test score higher than train score is not uncommon. Since the value is not significantly higher than the train recall, the reasons for this could be the test set having a different distribution of data than the training set, or the model performing better on the test set due to chance\n",
        "*   **31 predictions out of all the 102 patients having risk of CHD were false**\n",
        "*   **age is the most important feature for risk prediction of CHD, while BMI is the least important**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWUcIryGhdT9"
      },
      "outputs": [],
      "source": [
        "for score in lr_scores:\n",
        "  scores[score].append(lr_scores[score] * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJenfFQ4AEuv"
      },
      "source": [
        "### ML Model - 2 - XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W_wOkuqmTyO"
      },
      "outputs": [],
      "source": [
        "# Defining the Hyperparameters and scoring metric\n",
        "cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3, random_state = 42)\n",
        "scorer = make_scorer(recall_score, average = 'binary')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzZ89Wb8AJtH"
      },
      "outputs": [],
      "source": [
        "# Defining the Hyperparameters\n",
        "params_xgb = {\n",
        "              'n_estimators':[50, 100],\n",
        "              'max_depth':[3, 4],\n",
        "              'learning_rate':[0.01, 0.02]\n",
        "              }\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(random_state = 42)\n",
        "xgb_model = GridSearchCV(xgb_model, params_xgb, cv = cv, scoring = scorer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8bkb0dSBC_r"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "%%time\n",
        "xgb_scores, xgb_test_preds, xgb_model = model_train_test(xgb_model, X_train_final, Y_train_final, X_test_final, Y_test, gs = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3spd7uqDLi3"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(classification_report(Y_test, xgb_test_preds, target_names=['class-0', 'class-1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DKsthN7EyhG"
      },
      "outputs": [],
      "source": [
        "# Printing model scores\n",
        "print_scores(model_name = model_names[2], model_scores = xgb_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh3tO7KuGqwS"
      },
      "outputs": [],
      "source": [
        "# Displaying feature importances\n",
        "xgb_importances = pd.Series(xgb_model.feature_importances_, index = X.columns)\n",
        "plt.figure(figsize = (11, 6))\n",
        "ax = xgb_importances.sort_values(ascending = False).plot(kind = 'bar')\n",
        "ax.set(xlabel = 'Features', ylabel = 'Feature importances')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIXJHmOGG1bz"
      },
      "source": [
        "The following results can be observed from the XGBoost model:\n",
        "*   **Train recall of 80.55%  and Test Recall of  78.43%**\n",
        "*   **Train ROC-AUC score of 67 % and Test Recall of 66.21%**\n",
        "*   **22 predictions out of all the 102 patients having risk of CHD were false**\n",
        "*   **The XGBoost model also predicts age to be the most important feature for risk prediction of CHD, while BMI, heartRate and sex are the least important**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K11rduYkEtDo"
      },
      "outputs": [],
      "source": [
        "for score in xgb_scores:\n",
        "  scores[score].append(xgb_scores[score] * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3 - Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# Defining the Hyperparameters\n",
        "params_dt = {\n",
        "              'max_depth' : [3, 4, 5],\n",
        "              'min_samples_split':[10, 20, 25, 30],\n",
        "              'min_samples_leaf':[10, 20, 25, 30]\n",
        "              }\n",
        "\n",
        "dt_model = DecisionTreeClassifier(criterion= 'entropy', random_state = 42)\n",
        "dt_models = GridSearchCV(dt_model, params_dt, cv = cv, scoring = scorer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y4lfM0Qpo6c"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "%%time\n",
        "dt_scores, dt_test_preds, dt_model = model_train_test(dt_models, X_train_final, Y_train_final, X_test_final, Y_test, gs = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2nP2cQIpw-w"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(classification_report(Y_test, dt_test_preds, target_names=['class-0', 'class-1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdignTUtp0so"
      },
      "outputs": [],
      "source": [
        "# Printing the model scores\n",
        "print_scores(model_name = model_names[2], model_scores = dt_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNT3d48uGGyz"
      },
      "outputs": [],
      "source": [
        "# Displaying the Feature importances\n",
        "dt_importances = pd.Series(dt_model.feature_importances_, index = X.columns)\n",
        "plt.figure(figsize = (11, 6))\n",
        "ax = dt_importances.sort_values(ascending = False).plot(kind = 'bar')\n",
        "ax.set(xlabel = 'Features', ylabel = 'Feature importances')\n",
        "display_vals(ax)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the decision tree\n",
        "from sklearn import tree\n",
        "graph = Source(tree.export_graphviz(dt_model, out_file = None, feature_names = X.columns, class_names=['0', '1'] , filled = True))\n",
        "display(SVG(graph.pipe(format = 'svg')))\n",
        "\n"
      ],
      "metadata": {
        "id": "eiLJLTKYQNyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MichbJ9VGqaL"
      },
      "source": [
        "The following results can be observed from the Decision Tree model:\n",
        "*   **Train recall of 90.19% and Test Recall of 87.25%**\n",
        "*   **Train ROC-AUC score of 66.22% and Test Recall of 64.55%**\n",
        "*   **13 predictions out of all the 102 patients having risk of CHD were false**\n",
        "*   **age is again the most important feature for risk prediction of CHD, while sex, BMI and diabetes_grade are the least important. Since depth of the tree was 4 (as also seen in the plot above), the model did not split on the latter 3 variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J06Aw1BMp6sR"
      },
      "outputs": [],
      "source": [
        "for score in dt_scores:\n",
        "  scores[score].append(dt_scores[score] * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRqyaB0ov50W"
      },
      "source": [
        "### 1. Which HyperParameter Tuning and Cross Validation Technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter Tuning Technique"
      ],
      "metadata": {
        "id": "e5WyxV1XQl2_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w95dPJOcv50W"
      },
      "source": [
        "*   Algorithms like **GridSearch** was introduced to automate the process of running the model on various desired combinations of components that the user wishes to optimise, instead of manually running through every combination which is not only time consuming, but also requires regular involvement of the user.\n",
        "\n",
        "*   In this case, the **GridSearch** was used since the maximum time taken up by a model for training was 11mins (by Random Forest). While initially models like XGBoost took up a lot of time, it produced results which were overfitting. Hence, the *n_estimators, max_depth* parameters were brought down in number, thus considerably reducing the model training time. For these reasons, GridSearch was used."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross Validation Technique"
      ],
      "metadata": {
        "id": "ayrGE9VTQrim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the hyperparameter tuning is performed on an imbalanced dataset, it is generally recommended to use **RepeatedStratifiedKFold** instead of StratifiedKFold. This is because the former provides a more robust estimate of model performance by repeating the cross-validation process with different random splits of the data. This can help to mitigate the impact of class imbalance on the performance estimate."
      ],
      "metadata": {
        "id": "uYOHUXe1QuSn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr0obDj7NY-P"
      },
      "source": [
        "### 2. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqK6v4XNY-Q"
      },
      "source": [
        "*   As stated earlier, the **Recall** was chosen as the evaluation metric for comparison between models. The **Recall** is defined as below\n",
        "\\begin{align}\n",
        "Recall = \\frac{TruePositive} {True Positive + False Negative}\n",
        "\\end{align}\n",
        "where **True Positive** is the number of correctly predicted patients with CHD risk, while **False Negative** is the number of patients who have a risk of CHD but were wrongly predicted to not have any.\n",
        "\n",
        "*   Recall is a useful metric in CHD risk prediction because it focuses on the model's ability to correctly identify individuals who are at high risk for CHD. In other words, recall measures the proportion of individuals correctly identified as being at high risk out of all individuals who actually have high cardiovascular risk.\n",
        "\n",
        "*   In the context of cardiovascular risk prediction, it is important to identify individuals who are at high risk so that appropriate interventions can be taken to prevent or manage their risk. False negatives (i.e., individuals who are at high risk but are not correctly identified as such) can lead to missed opportunities for prevention or treatment, and may result in adverse health outcomes. Therefore, a high recall rate is desirable in cardiovascular risk prediction models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 3. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQeIthLRHQZJ"
      },
      "outputs": [],
      "source": [
        "# Comparing the evaluation metrics from each model\n",
        "results_df = pd.DataFrame(scores, index = model_names)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wid1RcxhJXlU"
      },
      "outputs": [],
      "source": [
        "# # Saving the result dataframe\n",
        "results_df.to_csv('results_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3-ffsK5KGrt"
      },
      "outputs": [],
      "source": [
        "# Plotting the train and test Recalls and choosing optimum model\n",
        "results_df[['Test Recall', 'Train Recall']].plot(kind = 'barh', figsize = (11, 6))\n",
        "plt.xlabel('Recall (%)')\n",
        "plt.xlim((0, 100))\n",
        "plt.xticks([0, 20, 40, 60, 80, 100, results_df['Test Recall'].max()])\n",
        "plt.axvline(results_df['Test Recall'].max(), color = 'red', linestyle = '--')\n",
        "plt.legend(bbox_to_anchor = (1, 0.5))\n",
        "plt.show()\n",
        "\n",
        "best_model = results_df[results_df['Test Recall'] == results_df['Test Recall'].max()].index[0]\n",
        "print(f'\\nThe model with maximum Test Recall is the {best_model} model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFX5G4J53J3X"
      },
      "source": [
        "The **Decision Tree** Model is the best model in this case when compared on the basis of **Test Recall**. It is to be noted that, while this model may not have the highest **Test ROC-AUC score**, almost all the models scored at a similar range in this metric (~65%). Hence, only comparing the **Test Recalls** would be apt in this case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 4. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Even though the model can be interpreted using the Decision tree plot earlier, using a model explainability tool can help intuitively visualise and interpret the model predictions\n",
        "*   The explainability tool used here is **SHapley Additive exPlanations**, or **SHAP** in short. It is chosen because it is a very consistent, unbiased explainability tool which provides intuitive visualisation of model predictions which allow users to easily understand the contribution of each feature to the final prediction\n",
        "*   **SHAP** provides insights into the overall behavior of the model."
      ],
      "metadata": {
        "id": "KvxsqniCSXCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "explainer = shap.TreeExplainer(dt_model)\n",
        "\n",
        "\n",
        "shap_values = explainer.shap_values(X_test_final)\n",
        "\n",
        "print(f\"SHAP values type: {type(shap_values)}\")\n",
        "if isinstance(shap_values, list):\n",
        "    print(f\"SHAP values length: {len(shap_values)}\")\n",
        "    print(f\"Class 0 shape: {shap_values[0].shape}\")\n",
        "    print(f\"Class 1 shape: {shap_values[1].shape}\")\n",
        "\n",
        "if isinstance(shap_values, list) and len(shap_values) == 2:\n",
        "    shap_values = shap_values[1]\n",
        "elif len(shap_values.shape) == 3:\n",
        "    shap_values = shap_values[..., 1]\n",
        "print(f\"Final SHAP values shape: {shap_values.shape}\")\n",
        "print(f\"Number of features: {len(X.columns)}\")\n",
        "\n",
        "mean_shap = pd.Series(np.abs(shap_values).mean(axis=0))\n",
        "\n",
        "shap_df = pd.DataFrame({\n",
        "    'features': X.columns,\n",
        "    'importance': mean_shap\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(shap_df['features'], shap_df['importance'], color='#1f77b4')\n",
        "plt.xlabel('Mean Absolute SHAP Value (Impact on CHD Risk)')\n",
        "plt.title('Feature Importance for CHD Risk Prediction')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ru17kGdVy6DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "The feature importances plot shows that age is the most important factor for a higher risk of CHD, while sex, BMI and diabetes levels are the least important. This is a similar result as the Feature importances plot in the [Decision Tree model training section](#scrollTo=UNT3d48uGGyz&line=4&uniqifier=1). Both predict that age is the most important factor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "joblib.dump(dt_model, 'dt_model_final.pkl')"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "model = joblib.load('dt_model_final.pkl')"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The **Cardiovascular Risk Prediction** project aimed to develop a machine learning model to predict the 10-year risk of Coronary Heart Disease (CHD) using the Framingham dataset. The project involved comprehensive data preprocessing, feature engineering, and the implementation of multiple classification models to achieve the best predictive performance. Below are the key takeaways:\n",
        "\n",
        "### **Key Insights and Findings:**\n",
        "1. **Data Preprocessing:**\n",
        "   - Missing values were imputed using realistic, research-backed methods (e.g., median imputation for continuous variables and logical rules for categorical variables like `BPMeds`).\n",
        "   - Outliers were handled using **Winsorising** to retain data integrity while limiting extreme values.\n",
        "   - Redundant features like `education`, `is_smoking`, and `prevalentStroke` were dropped to reduce dimensionality.\n",
        "   - Highly correlated features (`sysBP` and `diaBP`) were combined into **Mean Arterial Pressure (MAP)** to mitigate multicollinearity.\n",
        "\n",
        "2. **Feature Engineering:**\n",
        "   - **Glucose** levels were transformed into a categorical variable (`diabetes_grade`) to better capture risk categories (e.g., normal, pre-diabetes, diabetes).\n",
        "   - **Age** emerged as the most significant predictor of CHD risk, followed by `cigsPerDay` and `MAP`.\n",
        "\n",
        "3. **Model Performance:**\n",
        "   - Three models were evaluated: **Logistic Regression**, **Decision Tree**, and **XGBoost**.\n",
        "   - **Decision Tree** outperformed others with the highest **Test Recall (87.25%)**, ensuring the model correctly identified the majority of high-risk patients.\n",
        "   - **XGBoost** also performed well but was slightly less effective in recall compared to the Decision Tree.\n",
        "   - **Logistic Regression** provided interpretable results but had lower recall, making it less suitable for this use case.\n",
        "\n",
        "4. **Model Explainability:**\n",
        "   - **SHAP (SHapley Additive exPlanations)** was used to interpret the Decision Tree model, confirming that **age**, **smoking habits**, and **blood pressure** were the most influential factors in predicting CHD risk.\n",
        "   - The model’s transparency helps healthcare professionals understand risk factors and make informed decisions.\n",
        "\n",
        "### **Business Impact:**\n",
        "- The model can assist healthcare providers in **early identification of high-risk patients**, enabling timely interventions and preventive care.\n",
        "- By focusing on **recall**, the model minimizes **false negatives**, ensuring fewer high-risk cases are missed.\n",
        "- The insights can guide **personalized treatment plans** and **public health strategies** to reduce CHD incidence.\n",
        "\n",
        "### **Future Work:**\n",
        "\n",
        "- **Feature Expansion:** Incorporate more clinical and lifestyle factors (e.g., diet, exercise) for improved accuracy.\n",
        "- **Deployment:** Integrate the model into healthcare systems for real-time risk assessment.\n",
        "\n",
        "### **Final Takeaway:**\n",
        "The **Decision Tree model** was selected as the best-performing model due to its high recall and interpretability. This project highlights the importance of **data preprocessing, feature engineering, and model selection** in building an effective predictive healthcare tool. The insights gained can significantly contribute to **reducing cardiovascular risks** through early detection and intervention.  \n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}